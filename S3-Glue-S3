from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.sql.functions import col, lower, trim, regexp_replace, when
import boto3


sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init("final_s3_cleaning", args={})

s3_client = boto3.client("s3")
S3_BUCKET = "retail-etl"


# Functions to read data

def read_customers_data(path):
return spark.read.json(path)

def read_orders_data(path):
return spark.read.option("header", "true").csv(path)

def read_payments_data(path):
return spark.read.option("header", "true").csv(path)

def read_reviews_data(path):
return spark.read.json(path)

def read_products_data(path):
return spark.read.parquet(path)


# Cleaning functions

def clean_customers(df):
columns_order = ["customer_id", "name", "email", "phone_number", "age", "loyalty_status", "membership_tier", "address", "registration_date"]
df = df.withColumn("name", df["name"].cast("string"))
df = df.withColumn("email", lower(col("email")))
df = df.withColumn("email", when(col("email").rlike(r"^[^@]+@[^@]+\.[a-zA-Z]{2,}$"), col("email")).otherwise("invalid@email.com"))
df = df.withColumn("phone_number", trim(col("phone_number")))
df = df.withColumn("phone_number", regexp_replace(col("phone_number"), "^001-", "+1-"))
df = df.withColumn("phone_number", regexp_replace(col("phone_number"), "^([0-9]{3})[.]", "\\1-"))
df = df.withColumn("is_valid_format", col("phone_number").rlike("^[0-9+()\\-.]+$"))
df = df.withColumn("phone_number", when((col("is_valid_format") == False) | (col("phone_number").isNull()) | (col("phone_number") == ""), "Invalid").otherwise(col("phone_number")))
df = df.drop("is_valid_format")
df = df.withColumn("registration_date", regexp_replace(col("registration_date"), "/", "-"))
df = df.fillna({"phone_number": "Invalid", "loyalty_status": "Inactive", "membership_tier": "Standard", "address": "Not Provided"})

return df.select(columns_order).dropDuplicates(["customer_id"])


def clean_orders(df):
columns_order = ["order_id", "customer_id", "product_id", "order_date", "quantity", "total_price", "shipping_cost", "delivery_type", "promo_code_applied", "gift_wrapping", "payment_status"]
df = df.withColumn("order_date", regexp_replace(col("order_date"), "/", "-"))
df = df.withColumn("quantity", col("quantity").cast("int"))
df = df.withColumn("total_price", when(col("total_price") < 0, None).otherwise(col("total_price")).cast("double"))
df = df.fillna({"delivery_type": "Standard", "payment_status": "Pending"})
return df.select(columns_order).dropDuplicates()


def clean_payments(df):
columns_order = ["payment_id", "order_id", "amount", "payment_mode", "transaction_id", "bank_name", "currency", "payment_status"]
df = df.withColumn("amount", when(col("amount") < 0, None).otherwise(col("amount")).cast("double"))
df = df.fillna({"payment_mode": "Unknown", "payment_status": "Pending"})
return df.select(columns_order).dropDuplicates()


def clean_reviews(df):
columns_order = ["review_id", "order_id", "customer_id", "rating", "review_text", "sentiment_score", "review_length", "device_used", "verified_purchase"]
df = df.withColumn("review_text", trim(col("review_text")))
df = df.withColumn("sentiment_score", col("sentiment_score").cast("decimal(3,2)"))
df = df.withColumn("review_length", when(col("review_length") < 0, None).otherwise(col("review_length")).cast("int"))
df = df.fillna({"verified_purchase": "No"})
return df.select(columns_order).dropDuplicates()


def clean_products(df):
columns_order = ["product_id", "name", "brand", "category", "price", "discount_percentage", "supplier_id", "rating_avg", "inventory_count"]
df = df.withColumn("price", when(col("price") < 0, None).otherwise(col("price")).cast("decimal(10,2)"))
df = df.withColumn("discount_percentage", when((col("discount_percentage") < 0) | (col("discount_percentage") > 100), None).otherwise(col("discount_percentage")))
df = df.withColumn("inventory_count", when(col("inventory_count") < 0, None).otherwise(col("inventory_count")).cast("int"))
df = df.fillna({"brand": "Unknown", "category": "Miscellaneous", "supplier_id": "Not Available"})
return df.select(columns_order).dropDuplicates()


# Writing cleaned data while maintaining structure

def save_to_s3(df, filename):
temp_s3_path = f"s3://{S3_BUCKET}/temp/{filename}/"
final_key = f"staging/{filename}.parquet"
final_s3_path = f"s3://{S3_BUCKET}/{final_key}"

df.coalesce(1).write.mode("overwrite").parquet(temp_s3_path)

response = s3_client.list_objects_v2(Bucket=S3_BUCKET, Prefix=f"temp/{filename}/")
temp_files = [obj["Key"] for obj in response.get("Contents", []) if obj["Key"].endswith(".parquet")]
if not temp_files:
raise Exception(f"No Parquet file found in {temp_s3_path}")

temp_file_key = temp_files[0]

s3_client.copy_object(
Bucket=S3_BUCKET,
CopySource=f"{S3_BUCKET}/{temp_file_key}",
Key=final_key
)

s3_client.delete_object(Bucket=S3_BUCKET, Key=temp_file_key)
print(f"File moved to: {final_s3_path}")


# Processing and saving cleaned data

customers_df = clean_customers(read_customers_data("s3://retail-etl/raw-data/customers/customers.json"))

orders_df = clean_orders(read_orders_data("s3://retail-etl/raw-data/orders/orders.csv"))

payments_df = clean_payments(read_payments_data("s3://retail-etl/raw-data/payments/payments.csv"))

reviews_df = clean_reviews(read_reviews_data("s3://retail-etl/raw-data/reviews/reviews.json"))

products_df = clean_products(read_products_data("s3://retail-etl/raw-data/products/products.parquet"))


save_to_s3(customers_df, "customers")

save_to_s3(orders_df, "orders")

save_to_s3(payments_df, "payments")

save_to_s3(reviews_df, "reviews")

save_to_s3(products_df, "products")


job.commit()
